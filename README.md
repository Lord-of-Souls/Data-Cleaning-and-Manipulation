# Data Cleaning and Manipulation Project

## Description
This project focuses on the critical initial stages of the data science pipeline: data preprocessing and exploratory analysis. Using Python, the project transforms raw, "messy" data into a clean, reliable format suitable for extracting meaningful business or research insights.

## Project's Objective
The primary goal is to perform comprehensive data cleaning and manipulation on a raw dataset, ensuring data integrity and preparing it for accurate analysis and visualization.

## Results
- A sanitized dataset free of inconsistencies and errors.
- Visualizations highlighting key trends and patterns discovered during analysis.
- Clear, data-driven conclusions derived from the processed information.

## Methodology
The workflow follows a standard data preparation protocol:
1. **Data Inspection:** Identifying structural issues, missing values, and anomalies.
2. **Preprocessing:** Handling null values, correcting data types, and removing duplicates.
3. **Manipulation:** Filtering, grouping, and aggregating data to reveal specific insights.
4. **Analysis:** Applying statistical methods to draw conclusions from the cleaned data.


## Utilized Tools
- **Language:** [Python ](https://www.python.org)
- **Environment:** [Jupyter Notebook](https://jupyter.org) (Project files in `.ipynb` format)
- **Libraries:** [Pandas](https://pandas.pydata.org)

## Acquired/Developed Abilities
- **Feature Engineering:** Creating new variables from existing data.
- **Data Integrity:** Techniques for identifying and handling outliers and missing data.
- **Data Transformation:** Reshaping datasets using pivots and merges.
- **Analytical Thinking:** Translating raw numbers into actionable conclusions.

## Upgrades to be Made
- [ ] Implement automated cleaning pipelines for larger datasets.
- [ ] Integrate advanced statistical testing (e.g., hypothesis testing).
- [ ] Create an interactive dashboard using Streamlit or Plotly.

## How to Run It
You can run the project files in two ways:

### Option 1: Google Colab
1. Upload the `.ipynb` files directly to [Google Colab](https://colab.research.google.com).
2. Run the cells sequentially.

### Option 2: Local Environment (VS Code)
1. Ensure you have [Python](https://www.python.orgdownloads/) installed.
2. Install the **Jupyter Extension** in VS Code.
3. Open the `.ipynb` file and select your Python interpreter.

---
## Contact & Contribution
If you want to contribute or have any questions, feel free to reach out:
- [**GitHub:**](https://github.com/Lord-of-Souls)
- [**Linkedin:**](www.linkedin.com/in/lucasfranciscon)
